---
permalink: /
title: "Kaiwen Zhou"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

This is Kaiwen Zhou, a final-year Ph.D student at the University of California, Santa Cruz, fortunately advised by Prof. [Xin (Eric) Wang](https://eric-xw.github.io/). My current research focuses on **Responsible AI and AI agents**, aiming to build **Safe and Aligned AGI** in the long run. Below is a list of research areas I've worked on (<span style="color: purple;">purple</span> denotes first-author contributions):

1. **LLM Post-training (SFT&RL)**: <a href="https://arxiv.org/abs/2505.16186" style="color: purple; text-decoration: none;">SafeKey</a> (EMNLP 2025), <a href="https://arxiv.org/abs/2510.26037" style="color: purple; text-decoration: none;">SIRAJ</a> (EACL 2026 Findings)
2. **Safety Evaluation and Red-teaming**: <a href="https://arxiv.org/abs/2502.12659" style="color: purple; text-decoration: none;">R1 Safety Eval</a> (IJCNLP-AACL 2025), <a href="https://arxiv.org/abs/2410.06172" style="color: purple; text-decoration: none;">Multimodal Situational Safety</a> (ICLR 2025), <a href="https://arxiv.org/abs/2601.06663" style="color: purple; text-decoration: none;">SafePro</a>
3. **Responsible Embodied Agent**: <a href="https://arxiv.org/abs/2203.14936" style="color: purple; text-decoration: none;">FedVLN</a> (ECCV 2022), <a href="https://arxiv.org/pdf/2211.14769.pdf" style=" text-decoration: none;">Navigation as the Attacker Wishes</a> (NAACL 2024), <a href="https://arxiv.org/abs/2410.06172" style="color: purple; text-decoration: none;">Multimodal Situational Safety</a> (ICLR 2025)
4. **AI Agents:** <a href="https://arxiv.org/abs/2301.13166" style="color: purple; text-decoration: none;">ESC</a> (ICML 2023), <a href="https://arxiv.org/abs/2208.13266" style="color: purple; text-decoration: none;">JARVIS</a> (NeSy 2025 Oral), <a href="https://arxiv.org/abs/2510.05571" style=" text-decoration: none;">EvoPresent</a>
5. **Multimodal Understanding & Reasoning**: <a href="https://arxiv.org/pdf/2310.05872.pdf" style="color: purple; text-decoration: none;">ViCor</a> (ACL Findings 2024), <a href="https://arxiv.org/abs/2401.15847" style="text-decoration: none;">Multipanel VQA</a> (ACL 2024)

Before joining UCSC, I received my bachelor's degree in statistics from Zhejiang University.

**<span style="color: red;">I am now on the job market! I would be happy to discuss any opportunities that may be a good fit.</span>**

News
======
* Our SIRAJ paper is acceepted by EACL 2026 findings!(01/2026)
* <span style="color: red;">Selected for MATS and the Anthropic Fellows Program for AI Safety Research!</span> (12/2025)
* Our SafeKey paper is accepted by EMNLP 2025!(08/2025)
* Invited talk at Microsoft on safety reasoning!(06/2025)
* Honored to receive UCSC Dissertation-Year Fellowship to support my research on Trustworthy AI!(06/2025)
* I will join Microsoft as a research intern this summer!(03/2025)
* Our MSSBench paper is accepted by ICLR 2025!(01/2025)
* Two papers are accepted by ACL 2024!(05/2024)
* One paper is accepted by NAACL 2024!(03/2024)
* Our SlugJARVIS team won the third place in the first-ever [Amazon Alexa SimBot challenge](https://www.linkedin.com/feed/update/urn:li:activity:7072693926784077824/)! (06/2023)
* Our ESC paper is accepted by ICML 2023!(04/2023)
* ....

Selected Publications
======
**SafePro: Evaluating the Safety of Professional-Level AI Agents** <br />
**Kaiwen Zhou**, Shreedhar Jangam*, Ashwin Nagarajan*, Tejas Polu*, Suhas Oruganti, Chengzhi Liu, Ching-Chen Kuo, Yuting Zheng, Sravana Narayanaraju, Xin Eric Wang <br />
Arxiv 2026 <br />
\[[Paper](https://arxiv.org/abs/2601.06663)\] \[[Website](https://safeprobench.github.io/safepro/)\] \[[Code](https://github.com/eric-ai-lab/SafePro)\] \[[Data](https://github.com/eric-ai-lab/SafePro)\]

**SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning** <br />
**Kaiwen Zhou**, Ahmed Elgohary, A S M Iftekhar, Amin Saied <br />
EACL 2026 Findings <br />
\[[Paper](https://arxiv.org/abs/2510.26037)\]

**Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations** <br />
Chengzhi Liu\*, Yuzhe Yang\*, **Kaiwen Zhou**, Zhen Zhang, Yue Fan, Yannan Xie, Peng Qi, Xin Eric Wang <br /> 
Arxiv 2025 <br />
\[[Paper](https://arxiv.org/pdf/2510.05571)\] \[[Website](https://evopresent.github.io/)\] \[[Code](https://github.com/eric-ai-lab/EvoPresent)\] \[[Data](https://huggingface.co/datasets/TobyYang7/EvoPresent)\]

**SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning** <br />
**Kaiwen Zhou**, Xuandong Zhao, Gaowen Liu, Jayanth Srinivasa, Aosong Feng, Dawn Song, Xin Eric Wang <br /> 
EMNLP 2025 <br />
\[[Paper](https://arxiv.org/abs/2505.16186)\] \[[Website](https://safekeylrm.github.io/)\] \[[Code](https://github.com/eric-ai-lab/SafeKey/)\] \[[Models](https://huggingface.co/collections/kzhou35/safekey-682e1fe29f845acd875c0c8c)\]

**The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1** <br />
**Kaiwen Zhou**, Chengzhi Liu, Xuandong Zhao, Shreedhar Jangam, Jayanth Srinivasa, Gaowen Liu, Dawn Song, Xin Eric Wang <br /> 
IJCNLP-AACL 2025 <br />
\[[Paper](https://arxiv.org/abs/2502.12659)\] \[[Website](https://r1-safety.github.io/)\]

**Multimodal Situational Safety** <br />
**Kaiwen Zhou**\*, Chengzhi Liu\*, Xuandong Zhao, Anderson Compalas, Dawn Song, Xin Eric Wang <br /> 
ICLR 2025 <br />
NeurIPS Workshop on RBFM 2024 **Oral** <br /> 
\[[Paper](https://arxiv.org/abs/2410.06172)\] \[[Website](https://mssbench.github.io/)\] \[[Code](https://github.com/eric-ai-lab/MSSBench)\] \[[Data](https://huggingface.co/datasets/kzhou35/mssbench/tree/main)\]

**Muffin or Chihuahua? Challenging Large Vision-Language Models with Multipanel VQA** <br />
Yue Fan, Jing Gu, **Kaiwen Zhou**, Qianqi Yan, Shan Jiang, Ching-Chen Kuo, Xinze Guan, Xin Eric Wang <br /> 
ACL 2024 <br /> 
\[[Paper](https://arxiv.org/abs/2401.15847)\] \[[Website](https://sites.google.com/view/multipanelvqa/home)\]

**ViCor: Bridging Visual Understanding and Commonsense Reasoning with Large Language Models**  <br /> 
**Kaiwen Zhou**, Kwonjoon Lee, Teruhisa Misu, Xin Eric Wang  <br /> 
Findings of ACL 2024 <br /> 
\[[Paper](https://arxiv.org/pdf/2310.05872.pdf)\]

**Navigation as the Attacker Wishes? Towards Building Byzantine-Robust Embodied Agents under Federated Learning** <br /> 
Yunchao Zhang, Zonglin Di, **Kaiwen Zhou**, Cihang Xie, Xin Eric Wang <br /> 
NAACL 2024 <br /> 
\[[Paper](https://arxiv.org/pdf/2211.14769.pdf)\]

**ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation**  <br /> 
**Kaiwen Zhou**, Kaizhi Zheng, Connor Pryor, Yilin Shen, Hongxia Jin, Lise Getoor, Xin Eric Wang  <br /> 
ICML 2023 <br /> 
\[[Paper](https://arxiv.org/abs/2301.13166)\] \[[Website](https://sites.google.com/ucsc.edu/escnav/home)\]<br /> 

**FedVLN: Privacy-preserving Federated Vision-and-Language Navigation**  <br /> 
**Kaiwen Zhou**, Xin Eric Wang  <br /> 
ECCV 2022 <br /> 
\[[Paper](https://arxiv.org/abs/2203.14936)\]  \[[Code](https://github.com/eric-ai-lab/FedVLN)\] <br /> 

**JARVIS: A Neuro-Symbolic Commonsense Reasoning Framework for Conversational Embodied Agents**  <br /> 
Kaizhi Zheng\*, **Kaiwen Zhou**\*, Jing Gu\*, Yue Fan\*, Zonglin Di\*, Jialu Wang, Xuehai He, Xin Eric Wang <br /> 
SoCal NLP 2022, NeSy 2025 **Oral**  <br /> 
Winner Model of the Alexa Prize SimBot Public Benchmark Challenge  <br /> 
\[[Paper](https://arxiv.org/abs/2208.13266)\] <br /> 

Service
======
**Reviewer**  <br /> 
NeurIPS 2023, ICLR 2024, ICML 2024, ICLR 2025, ICLR 2026

**Area Chair**  <br /> 
ARR Oct 2025

